{"cells":[{"cell_type":"markdown","metadata":{"id":"D0ZYS7EaM7kP"},"source":["# CS 584 Assignment 4 -- Sequence to Sequence Models\n","\n","#### Name: Nyrah Balabanian\n","#### Stevens ID: 20005955"],"id":"D0ZYS7EaM7kP"},{"cell_type":"markdown","metadata":{"id":"TPPt_5vUM7kX"},"source":["## In this assignment, you are required to follow the steps below:\n","1. Review the lecture slides.\n","2. Implement the seq2seq (translation) model.\n","\n","**Before you start**\n","- Please read the code very carefully.\n","- Install these packages using the following command.\n","```console\n","pip install -r requirements.txt\n","```\n","- It's better to train the Tensorflow model with GPU and CUDA. If they are not available on your local machine, please consider Google CoLab. You can check `CoLab.md` in this assignments.\n","- You are **NOT** allowed to use other packages unless otherwise specified.\n","- You are **ONLY** allowed to edit the code between `# Start your code here` and `# End` for each block."],"id":"TPPt_5vUM7kX"},{"cell_type":"code","source":["pip install -r /content/drive/MyDrive/a4-code-data/requirements.txt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IRJTGmT7aQPz","executionInfo":{"status":"ok","timestamp":1713892487630,"user_tz":240,"elapsed":27726,"user":{"displayName":"Nyrah Balabanian","userId":"13414016456258284830"}},"outputId":"767fbdc2-63c6-46cc-8de2-09114951112e"},"id":"IRJTGmT7aQPz","execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting datasets (from -r /content/drive/MyDrive/a4-code-data/requirements.txt (line 1))\n","  Downloading datasets-2.19.0-py3-none-any.whl (542 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.0/542.0 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting evaluate (from -r /content/drive/MyDrive/a4-code-data/requirements.txt (line 2))\n","  Downloading evaluate-0.4.1-py3-none-any.whl (84 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting jupyterlab (from -r /content/drive/MyDrive/a4-code-data/requirements.txt (line 3))\n","  Downloading jupyterlab-4.1.6-py3-none-any.whl (11.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.4/11.4 MB\u001b[0m \u001b[31m49.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/a4-code-data/requirements.txt (line 4)) (3.7.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/a4-code-data/requirements.txt (line 5)) (1.25.2)\n","Collecting sacrebleu (from -r /content/drive/MyDrive/a4-code-data/requirements.txt (line 6))\n","  Downloading sacrebleu-2.4.2-py3-none-any.whl (106 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.7/106.7 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/a4-code-data/requirements.txt (line 7)) (2.15.0)\n","Collecting tensorflow-addons (from -r /content/drive/MyDrive/a4-code-data/requirements.txt (line 8))\n","  Downloading tensorflow_addons-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (611 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.8/611.8 kB\u001b[0m \u001b[31m56.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tokenizers in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/a4-code-data/requirements.txt (line 9)) (0.19.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 1)) (3.13.4)\n","Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 1)) (14.0.2)\n","Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 1)) (0.6)\n","Collecting dill<0.3.9,>=0.3.0 (from datasets->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 1))\n","  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 1)) (2.0.3)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 1)) (2.31.0)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 1)) (4.66.2)\n","Collecting xxhash (from datasets->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 1))\n","  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting multiprocess (from datasets->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 1))\n","  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: fsspec[http]<=2024.3.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 1)) (2023.6.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 1)) (3.9.5)\n","Collecting huggingface-hub>=0.21.2 (from datasets->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 1))\n","  Downloading huggingface_hub-0.22.2-py3-none-any.whl (388 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m388.9/388.9 kB\u001b[0m \u001b[31m47.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 1)) (24.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 1)) (6.0.1)\n","Collecting responses<0.19 (from evaluate->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 2))\n","  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n","Collecting async-lru>=1.0.0 (from jupyterlab->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 3))\n","  Downloading async_lru-2.0.4-py3-none-any.whl (6.1 kB)\n","Collecting httpx>=0.25.0 (from jupyterlab->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 3))\n","  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting ipykernel>=6.5.0 (from jupyterlab->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 3))\n","  Downloading ipykernel-6.29.4-py3-none-any.whl (117 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.1/117.1 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: jinja2>=3.0.3 in /usr/local/lib/python3.10/dist-packages (from jupyterlab->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 3)) (3.1.3)\n","Requirement already satisfied: jupyter-core in /usr/local/lib/python3.10/dist-packages (from jupyterlab->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 3)) (5.7.2)\n","Collecting jupyter-lsp>=2.0.0 (from jupyterlab->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 3))\n","  Downloading jupyter_lsp-2.2.5-py3-none-any.whl (69 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.1/69.1 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting jupyter-server<3,>=2.4.0 (from jupyterlab->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 3))\n","  Downloading jupyter_server-2.14.0-py3-none-any.whl (383 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m383.3/383.3 kB\u001b[0m \u001b[31m45.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting jupyterlab-server<3,>=2.19.0 (from jupyterlab->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 3))\n","  Downloading jupyterlab_server-2.27.1-py3-none-any.whl (59 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.3/59.3 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: notebook-shim>=0.2 in /usr/local/lib/python3.10/dist-packages (from jupyterlab->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 3)) (0.2.4)\n","Requirement already satisfied: tomli>=1.2.2 in /usr/local/lib/python3.10/dist-packages (from jupyterlab->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 3)) (2.0.1)\n","Requirement already satisfied: tornado>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from jupyterlab->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 3)) (6.3.3)\n","Requirement already satisfied: traitlets in /usr/local/lib/python3.10/dist-packages (from jupyterlab->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 3)) (5.7.1)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 4)) (1.2.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 4)) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 4)) (4.51.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 4)) (1.4.5)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 4)) (9.4.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 4)) (3.1.2)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 4)) (2.8.2)\n","Collecting portalocker (from sacrebleu->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 6))\n","  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n","Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 6)) (2023.12.25)\n","Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 6)) (0.9.0)\n","Collecting colorama (from sacrebleu->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 6))\n","  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 6)) (4.9.4)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 7)) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 7)) (1.6.3)\n","Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 7)) (24.3.25)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 7)) (0.5.4)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 7)) (0.2.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 7)) (3.9.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 7)) (18.1.1)\n","Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 7)) (0.2.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 7)) (3.3.0)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 7)) (3.20.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 7)) (67.7.2)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 7)) (1.16.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 7)) (2.4.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 7)) (4.11.0)\n","Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 7)) (1.14.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 7)) (0.36.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 7)) (1.62.2)\n","Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 7)) (2.15.2)\n","Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 7)) (2.15.0)\n","Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 7)) (2.15.0)\n","Collecting typeguard<3.0.0,>=2.7 (from tensorflow-addons->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 8))\n","  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 7)) (0.43.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 1)) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 1)) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 1)) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 1)) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 1)) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 1)) (4.0.3)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.25.0->jupyterlab->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 3)) (3.7.1)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.25.0->jupyterlab->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 3)) (2024.2.2)\n","Collecting httpcore==1.* (from httpx>=0.25.0->jupyterlab->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 3))\n","  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.25.0->jupyterlab->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 3)) (3.7)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.25.0->jupyterlab->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 3)) (1.3.1)\n","Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.25.0->jupyterlab->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 3))\n","  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting comm>=0.1.1 (from ipykernel>=6.5.0->jupyterlab->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 3))\n","  Downloading comm-0.2.2-py3-none-any.whl (7.2 kB)\n","Requirement already satisfied: debugpy>=1.6.5 in /usr/local/lib/python3.10/dist-packages (from ipykernel>=6.5.0->jupyterlab->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 3)) (1.6.6)\n","Requirement already satisfied: ipython>=7.23.1 in /usr/local/lib/python3.10/dist-packages (from ipykernel>=6.5.0->jupyterlab->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 3)) (7.34.0)\n","Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.10/dist-packages (from ipykernel>=6.5.0->jupyterlab->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 3)) (6.1.12)\n","Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.10/dist-packages (from ipykernel>=6.5.0->jupyterlab->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 3)) (0.1.7)\n","Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.10/dist-packages (from ipykernel>=6.5.0->jupyterlab->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 3)) (1.6.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ipykernel>=6.5.0->jupyterlab->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 3)) (5.9.5)\n","Collecting pyzmq>=24 (from ipykernel>=6.5.0->jupyterlab->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 3))\n","  Downloading pyzmq-26.0.2-cp310-cp310-manylinux_2_28_x86_64.whl (919 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m920.0/920.0 kB\u001b[0m \u001b[31m70.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=3.0.3->jupyterlab->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 3)) (2.1.5)\n","Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core->jupyterlab->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 3)) (4.2.0)\n","Requirement already satisfied: argon2-cffi>=21.1 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 3)) (23.1.0)\n","Collecting jupyter-client>=6.1.12 (from ipykernel>=6.5.0->jupyterlab->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 3))\n","  Downloading jupyter_client-8.6.1-py3-none-any.whl (105 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.9/105.9 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting jupyter-events>=0.9.0 (from jupyter-server<3,>=2.4.0->jupyterlab->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 3))\n","  Downloading jupyter_events-0.10.0-py3-none-any.whl (18 kB)\n","Collecting jupyter-server-terminals>=0.4.4 (from jupyter-server<3,>=2.4.0->jupyterlab->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 3))\n","  Downloading jupyter_server_terminals-0.5.3-py3-none-any.whl (13 kB)\n","Requirement already satisfied: nbconvert>=6.4.4 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 3)) (6.5.4)\n","Requirement already satisfied: nbformat>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 3)) (5.10.4)\n","Collecting overrides>=5.0 (from jupyter-server<3,>=2.4.0->jupyterlab->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 3))\n","  Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n","Requirement already satisfied: prometheus-client>=0.9 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 3)) (0.20.0)\n","Requirement already satisfied: send2trash>=1.8.2 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 3)) (1.8.3)\n","Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 3)) (0.18.1)\n","Requirement already satisfied: websocket-client>=1.7 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 3)) (1.7.0)\n","Requirement already satisfied: babel>=2.10 in /usr/local/lib/python3.10/dist-packages (from jupyterlab-server<3,>=2.19.0->jupyterlab->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 3)) (2.14.0)\n","Collecting json5>=0.9.0 (from jupyterlab-server<3,>=2.19.0->jupyterlab->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 3))\n","  Downloading json5-0.9.25-py3-none-any.whl (30 kB)\n","Requirement already satisfied: jsonschema>=4.18.0 in /usr/local/lib/python3.10/dist-packages (from jupyterlab-server<3,>=2.19.0->jupyterlab->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 3)) (4.19.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 1)) (3.3.2)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 1)) (2.0.7)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 7)) (2.27.0)\n","Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 7)) (1.2.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 7)) (3.6)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 7)) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 7)) (3.0.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 1)) (2023.4)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 1)) (2024.1)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.25.0->jupyterlab->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 3)) (1.2.1)\n","Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 3)) (21.2.0)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 7)) (5.3.3)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 7)) (0.4.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 7)) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 7)) (1.3.1)\n","Collecting jedi>=0.16 (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 3))\n","  Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m50.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 3)) (4.4.2)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 3)) (0.7.5)\n","Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 3)) (3.0.43)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 3)) (2.16.1)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 3)) (0.2.0)\n","Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 3)) (4.9.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.19.0->jupyterlab->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 3)) (2023.12.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.19.0->jupyterlab->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 3)) (0.34.0)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.19.0->jupyterlab->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 3)) (0.18.0)\n","Collecting python-json-logger>=2.0.4 (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 3))\n","  Downloading python_json_logger-2.0.7-py3-none-any.whl (8.1 kB)\n","Collecting rfc3339-validator (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 3))\n","  Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl (3.5 kB)\n","Collecting rfc3986-validator>=0.1.1 (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 3))\n","  Downloading rfc3986_validator-0.1.1-py2.py3-none-any.whl (4.2 kB)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 3)) (4.12.3)\n","Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 3)) (6.1.0)\n","Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 3)) (0.7.1)\n","Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 3)) (0.4)\n","Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 3)) (0.3.0)\n","Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 3)) (0.8.4)\n","Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 3)) (0.10.0)\n","Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 3)) (1.5.1)\n","Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 3)) (1.2.1)\n","Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.3.0->jupyter-server<3,>=2.4.0->jupyterlab->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 3)) (2.19.1)\n","Requirement already satisfied: ptyprocess in /usr/local/lib/python3.10/dist-packages (from terminado>=0.8.3->jupyter-server<3,>=2.4.0->jupyterlab->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 3)) (0.7.0)\n","Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 3)) (0.8.4)\n","Collecting fqdn (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.19.0->jupyterlab->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 3))\n","  Downloading fqdn-1.5.1-py3-none-any.whl (9.1 kB)\n","Collecting isoduration (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.19.0->jupyterlab->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 3))\n","  Downloading isoduration-20.11.0-py3-none-any.whl (11 kB)\n","Collecting jsonpointer>1.13 (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.19.0->jupyterlab->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 3))\n","  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n","Collecting uri-template (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.19.0->jupyterlab->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 3))\n","  Downloading uri_template-1.3.0-py3-none-any.whl (11 kB)\n","Requirement already satisfied: webcolors>=1.11 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.19.0->jupyterlab->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 3)) (1.13)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 3)) (0.2.13)\n","Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 7)) (0.6.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 7)) (3.2.2)\n","Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 3)) (1.16.0)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 3)) (2.5)\n","Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 3)) (0.5.1)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 3)) (2.22)\n","Collecting arrow>=0.15.0 (from isoduration->jsonschema>=4.18.0->jupyterlab-server<3,>=2.19.0->jupyterlab->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 3))\n","  Downloading arrow-1.3.0-py3-none-any.whl (66 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting types-python-dateutil>=2.8.10 (from arrow>=0.15.0->isoduration->jsonschema>=4.18.0->jupyterlab-server<3,>=2.19.0->jupyterlab->-r /content/drive/MyDrive/a4-code-data/requirements.txt (line 3))\n","  Downloading types_python_dateutil-2.9.0.20240316-py3-none-any.whl (9.7 kB)\n","Installing collected packages: xxhash, uri-template, types-python-dateutil, typeguard, rfc3986-validator, rfc3339-validator, pyzmq, python-json-logger, portalocker, overrides, jsonpointer, json5, jedi, h11, fqdn, dill, comm, colorama, async-lru, tensorflow-addons, sacrebleu, responses, multiprocess, jupyter-server-terminals, jupyter-client, huggingface-hub, httpcore, arrow, isoduration, ipykernel, httpx, datasets, jupyter-events, evaluate, jupyter-server, jupyterlab-server, jupyter-lsp, jupyterlab\n","  Attempting uninstall: pyzmq\n","    Found existing installation: pyzmq 23.2.1\n","    Uninstalling pyzmq-23.2.1:\n","      Successfully uninstalled pyzmq-23.2.1\n","  Attempting uninstall: jupyter-client\n","    Found existing installation: jupyter-client 6.1.12\n","    Uninstalling jupyter-client-6.1.12:\n","      Successfully uninstalled jupyter-client-6.1.12\n","  Attempting uninstall: huggingface-hub\n","    Found existing installation: huggingface-hub 0.20.3\n","    Uninstalling huggingface-hub-0.20.3:\n","      Successfully uninstalled huggingface-hub-0.20.3\n","  Attempting uninstall: ipykernel\n","    Found existing installation: ipykernel 5.5.6\n","    Uninstalling ipykernel-5.5.6:\n","      Successfully uninstalled ipykernel-5.5.6\n","  Attempting uninstall: jupyter-server\n","    Found existing installation: jupyter-server 1.24.0\n","    Uninstalling jupyter-server-1.24.0:\n","      Successfully uninstalled jupyter-server-1.24.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","google-colab 1.0.0 requires ipykernel==5.5.6, but you have ipykernel 6.29.4 which is incompatible.\n","notebook 6.5.5 requires jupyter-client<8,>=5.3.4, but you have jupyter-client 8.6.1 which is incompatible.\n","notebook 6.5.5 requires pyzmq<25,>=17, but you have pyzmq 26.0.2 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed arrow-1.3.0 async-lru-2.0.4 colorama-0.4.6 comm-0.2.2 datasets-2.19.0 dill-0.3.8 evaluate-0.4.1 fqdn-1.5.1 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 huggingface-hub-0.22.2 ipykernel-6.29.4 isoduration-20.11.0 jedi-0.19.1 json5-0.9.25 jsonpointer-2.4 jupyter-client-8.6.1 jupyter-events-0.10.0 jupyter-lsp-2.2.5 jupyter-server-2.14.0 jupyter-server-terminals-0.5.3 jupyterlab-4.1.6 jupyterlab-server-2.27.1 multiprocess-0.70.16 overrides-7.7.0 portalocker-2.8.2 python-json-logger-2.0.7 pyzmq-26.0.2 responses-0.18.0 rfc3339-validator-0.1.4 rfc3986-validator-0.1.1 sacrebleu-2.4.2 tensorflow-addons-0.23.0 typeguard-2.13.3 types-python-dateutil-2.9.0.20240316 uri-template-1.3.0 xxhash-3.4.1\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DEjZgzeXanXN","executionInfo":{"status":"ok","timestamp":1713892441843,"user_tz":240,"elapsed":17131,"user":{"displayName":"Nyrah Balabanian","userId":"13414016456258284830"}},"outputId":"0b11bf20-e502-4300-c3f7-e13ff4eaeff9"},"id":"DEjZgzeXanXN","execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":3,"metadata":{"id":"OsAUzgCKM7ka","executionInfo":{"status":"ok","timestamp":1713892441844,"user_tz":240,"elapsed":16,"user":{"displayName":"Nyrah Balabanian","userId":"13414016456258284830"}}},"outputs":[],"source":["import sys\n","import os\n","\n","\n","def print_line(*args):\n","    \"\"\" Inline print and go to the begining of line\n","    \"\"\"\n","    args1 = [str(arg) for arg in args]\n","    str_ = ' '.join(args1)\n","    print('\\r' + str_, end='')"],"id":"OsAUzgCKM7ka"},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"988gujoVM7kd","executionInfo":{"status":"ok","timestamp":1713892448833,"user_tz":240,"elapsed":7004,"user":{"displayName":"Nyrah Balabanian","userId":"13414016456258284830"}},"outputId":"5e926f8f-836d-4a0d-e79a-7725b22e6b26"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"]},"metadata":{},"execution_count":4}],"source":["import tensorflow as tf\n","\n","\n","# If you are going to use GPU, make sure the GPU in in the output\n","tf.config.list_physical_devices('GPU')"],"id":"988gujoVM7kd"},{"cell_type":"code","execution_count":5,"metadata":{"id":"8uAQKtSqM7ke","executionInfo":{"status":"ok","timestamp":1713892448834,"user_tz":240,"elapsed":35,"user":{"displayName":"Nyrah Balabanian","userId":"13414016456258284830"}}},"outputs":[],"source":["from typing import List, Tuple, Union, Dict\n","\n","import numpy as np"],"id":"8uAQKtSqM7ke"},{"cell_type":"markdown","metadata":{"id":"ncMidrBsM7kf"},"source":["## 1. Data preparation (5 Points)"],"id":"ncMidrBsM7kf"},{"cell_type":"markdown","metadata":{"id":"kL9FnI4_M7kf"},"source":["### 1.1 Load and describe data"],"id":"kL9FnI4_M7kf"},{"cell_type":"markdown","metadata":{"id":"UfkiieHeM7kg"},"source":["Here, we use the [iwslt2017](https://huggingface.co/datasets/iwslt2017) dataset. More specifically, this translation task is from French to English: fr-en."],"id":"UfkiieHeM7kg"},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":365,"referenced_widgets":["10ae808974d34ae592bf4f381491afaa","bf658fbc41bb4ecd93e20b03e77fc79b","af8b67bf98d64270aae1f40e93065b4b","61f9bf4d822745d7a221817e48bc690c","5fd5bfb21a1046e586a0cd57ad1ea761","6863ab8ac12c401cb2369500e432d12e","20b20c6233c44cd289ac942d3100b19b","390e1188517241e6beac2b28b5f09620","083080f5e32b48a6b26c42f6df9f15a5","9dd728b6fb0548efb7656a20ad6d3829","30759874a3aa4986b9c5a1d8cc310fae","7c7716d2653f4547b4bac08da834bf22","989c7e1e1d944f45b60e0eb86b25bb4c","f65882355d324e2fbf5ddf1477d6e125","a12472216c314ac28cab8bc0bf657f73","2f31eba8cb904eb5bf46bbc60d07879a","c6a986f86849421da5a4d9354b297ffb","5a9228bb90f2403db9489ed6c571710b","7cd32c949af34f84b3df90768934f350","eeabf870c7584de8acd95eab52073b93","7b80c24a45bf4be69f9e28460449645f","be6abdcd63504b55a6e7da904e0eed4c","8da00cdfbac4449d87eb7feb65fd3754","4c74946272344b56ae2c616ea2f2e7e8","cac85ca90c2b4e248337446049d2c7bf","5de7cc4994cf4b58a12f3ec57aec5245","28f8c9521130423fbea46b169f31c33c","0b73f35e24e04702bd711da450a736ef","08080ce891cc41108e94cecff2e407af","7f1e14090ced4bd6a270ed980111d9d9","4bffdd20083240dd955cfad35fe536cb","f022531e81f94211a07ae69a0daee141","70e1771543ea43908ae760fe95b3f40a","32f5219406d346669b4c7a8e359fbfeb","f183456cfcc64b1a808ac653d4241ce9","5802a3c7581f4663b6455e20241302db","99eb7165a10044d7b5a125dd22f19c91","c5b59a24f34d47b994dc9728511f9506","3e798777046d4279b65cd50cca6f6ce4","6be4a58f70be448cac3b755c0e3a69a3","c7056a6877c84b76805ad2eb727fa385","88a280b4ea5546e79768cd6032da4f3d","467f985c76484771b5b78b21e725cca9","43f1cd0ca5414b5bb58a58e35b157cd9","8ce41633bfeb4217ae5881ab88f8ab93","622633fd4f87405e89842bc840114817","5c0f51043190479ba5b642550417294f","1fa4df4fcb784928982dd0c7dfde44ce","3c46aa9f15c9441fb57508b7948d50c5","0607f1bc4f9048dfb0662ae52928b20a","75a52f4711b74664906ec9f39587f690","a454db115a624c20b38f8970b8c85ef9","14f2298dde89424b902c297d23fea48f","fce3d5ac295b4d5ab8ee7c4ec3410870","2d33907246fd4105b997a6a4df42c9fb","694a76777ab84f8cb0016f93e773db88","3b9975b334de408cb7b69626c60c7017","7c1e5b398aa249bc88b08a2c391c6e82","7ee7eb62687142f28c8060bae51e0f92","aa9e8db0f6f24c22be9b58f717880742","cc55162c2f364195ba69d6cc06ba4e7a","c7dc632851044e2d82e9ff70a13ce5d6","ab91a11108bd469bb5daf0e15d477d9f","3b1af9069400407caa23ec56e8397399","f59e2cb658b34644bcbc8a5fc418b336","857d418d3bea42cd96e62ab78bdffcb2"]},"id":"7bUqP5tmM7kh","executionInfo":{"status":"ok","timestamp":1713892492646,"user_tz":240,"elapsed":5025,"user":{"displayName":"Nyrah Balabanian","userId":"13414016456258284830"}},"outputId":"68449cc6-71fe-4e39-8e44-b110646ef90a"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/datasets/load.py:2555: FutureWarning: 'ignore_verifications' was deprecated in favor of 'verification_mode' in version 2.9.1 and will be removed in 3.0.0.\n","You can remove this warning by passing 'verification_mode=no_checks' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading data:   0%|          | 0.00/30.1M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"10ae808974d34ae592bf4f381491afaa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading data:   0%|          | 0.00/1.09M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7c7716d2653f4547b4bac08da834bf22"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading data:   0%|          | 0.00/129k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8da00cdfbac4449d87eb7feb65fd3754"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Generating train split:   0%|          | 0/232825 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"32f5219406d346669b4c7a8e359fbfeb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Generating test split:   0%|          | 0/8597 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8ce41633bfeb4217ae5881ab88f8ab93"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Generating validation split:   0%|          | 0/890 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"694a76777ab84f8cb0016f93e773db88"}},"metadata":{}}],"source":["from datasets import load_dataset\n","# The load_dataset function is provided by the huggingface datasets\n","# https://huggingface.co/docs/datasets/index\n","\n","\n","dataset_path = os.path.join('a4-data', 'dataset')\n","dataset = load_dataset('iwslt2017', 'iwslt2017-en-fr', cache_dir=dataset_path, ignore_verifications=True)"],"id":"7bUqP5tmM7kh"},{"cell_type":"markdown","metadata":{"id":"LULLZO0NM7ki"},"source":["Let's first print some basic statistics of this dataset"],"id":"LULLZO0NM7ki"},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TbVuYD5MM7kj","executionInfo":{"status":"ok","timestamp":1713892495293,"user_tz":240,"elapsed":2655,"user":{"displayName":"Nyrah Balabanian","userId":"13414016456258284830"}},"outputId":"fe63ca2e-9c53-41c3-97a5-957acf87cdce"},"outputs":[{"output_type":"stream","name":"stdout","text":["DatasetDict({\n","    train: Dataset({\n","        features: ['translation'],\n","        num_rows: 232825\n","    })\n","    test: Dataset({\n","        features: ['translation'],\n","        num_rows: 8597\n","    })\n","    validation: Dataset({\n","        features: ['translation'],\n","        num_rows: 890\n","    })\n","})\n","232825 890 8597\n"]}],"source":["print(dataset)\n","print(len(dataset['train']['translation']), len(dataset['validation']['translation']), len(dataset['test']['translation']))"],"id":"TbVuYD5MM7kj"},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZCt5V7bbM7kj","executionInfo":{"status":"ok","timestamp":1713892499222,"user_tz":240,"elapsed":3935,"user":{"displayName":"Nyrah Balabanian","userId":"13414016456258284830"}},"outputId":"cfadfb90-890d-4753-b86a-005968eecf3a"},"outputs":[{"output_type":"stream","name":"stdout","text":["{'en': \"Thank you so much, Chris. And it's truly a great honor to have the opportunity to come to this stage twice; I'm extremely grateful.\", 'fr': \"Merci beaucoup, Chris. C'est vraiment un honneur de pouvoir venir sur cette scène une deuxième fois. Je suis très reconnaissant.\"}\n"]}],"source":["print(dataset['train']['translation'][0])"],"id":"ZCt5V7bbM7kj"},{"cell_type":"code","execution_count":11,"metadata":{"id":"kNco1CUAM7kk","executionInfo":{"status":"ok","timestamp":1713892500208,"user_tz":240,"elapsed":1012,"user":{"displayName":"Nyrah Balabanian","userId":"13414016456258284830"}}},"outputs":[],"source":["from tokenizers import Tokenizer\n","# The tokenizer is provided by the huggingface tokenizers\n","# https://huggingface.co/docs/tokenizers/index\n","# Here, I already pretrained a BPE tokenizer and you can simply load the json\n","# The token numbers of both English and French are 10,000\n","# All tokens should be lower-case.\n","\n","\n","en_tokenizer = Tokenizer.from_file('/content/drive/MyDrive/a4-code-data/a4-data/en_tokenizer.json')\n","fr_tokenizer = Tokenizer.from_file('/content/drive/MyDrive/a4-code-data/a4-data/fr_tokenizer.json')"],"id":"kNco1CUAM7kk"},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j1vvHQwsM7kl","executionInfo":{"status":"ok","timestamp":1713892500208,"user_tz":240,"elapsed":4,"user":{"displayName":"Nyrah Balabanian","userId":"13414016456258284830"}},"outputId":"96e96c93-1dbb-406e-8332-622b6618719b"},"outputs":[{"output_type":"stream","name":"stdout","text":["[0, 122, 279, 4987, 17, 1]\n","['<s>', 'Ġi', 'Ġlike', 'Ġsports', '.', '</s>']\n"]}],"source":["encoding = en_tokenizer.encode(\"i like sports.\")\n","print(encoding.ids)\n","print(encoding.tokens)\n","# >>> [0, 122, 279, 4987, 17, 1]\n","# >>> ['<s>', 'Ġi', 'Ġlike', 'Ġsports', '.', '</s>']"],"id":"j1vvHQwsM7kl"},{"cell_type":"markdown","metadata":{"id":"9lGpDX6sM7km"},"source":["Extract English and French sentences for training, validation, and test sets.\n","\n","Note: Every sentence is lower-case."],"id":"9lGpDX6sM7km"},{"cell_type":"code","execution_count":13,"metadata":{"id":"Jt1jEWovM7kn","executionInfo":{"status":"ok","timestamp":1713892504323,"user_tz":240,"elapsed":4117,"user":{"displayName":"Nyrah Balabanian","userId":"13414016456258284830"}}},"outputs":[],"source":["train_en_sentences, train_fr_sentences = zip(*[(pair['en'].lower(), pair['fr'].lower()) for pair in dataset['train']['translation']])\n","valid_en_sentences, valid_fr_sentences = zip(*[(pair['en'].lower(), pair['fr'].lower()) for pair in dataset['validation']['translation']])\n","test_en_sentences, test_fr_sentences = zip(*[(pair['en'].lower(), pair['fr'].lower()) for pair in dataset['test']['translation']])"],"id":"Jt1jEWovM7kn"},{"cell_type":"markdown","metadata":{"id":"-2uMjJKdM7ko"},"source":["### 1.2 Encode data (5 Points)"],"id":"-2uMjJKdM7ko"},{"cell_type":"code","execution_count":14,"metadata":{"id":"gJWeQMYHM7ko","executionInfo":{"status":"ok","timestamp":1713892504324,"user_tz":240,"elapsed":21,"user":{"displayName":"Nyrah Balabanian","userId":"13414016456258284830"}}},"outputs":[],"source":["def encode(tokenizer: 'Tokenizer', sentences: List[str]) -> List[List[int]]:\n","    \"\"\" Encode the sentences with the pretrained tokenizer.\n","        You can directly call `tokenizer.encode()` to encode the sentences.\n","        It will automatically add the <s> and </s> token.\n","\n","        Note: Please be carefull with the return value of the encode function.\n","\n","    Args:\n","        tokenizer: A pretrained en/fr tokenizer\n","        sentences: A list of strings\n","    Return:\n","        sent_token_ids: A list of token ids\n","    \"\"\"\n","    sent_token_ids = []\n","    n = len(sentences)\n","    for i, sentence in enumerate(sentences):\n","        if i % 100 == 0 or i == n - 1:\n","            print_line('Encoding with Tokenizer:', (i + 1), '/', n)\n","        # Start your code here\n","        encoded_sentence = tokenizer.encode(sentence)\n","        if not isinstance(encoded_sentence, list):\n","            encoded_sentence = encoded_sentence.ids\n","        sent_token_ids.append(encoded_sentence)\n","\n","        # End\n","    print_line('\\n')\n","    return sent_token_ids"],"id":"gJWeQMYHM7ko"},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AD1-td4rM7kp","executionInfo":{"status":"ok","timestamp":1713892557259,"user_tz":240,"elapsed":52955,"user":{"displayName":"Nyrah Balabanian","userId":"13414016456258284830"}},"outputId":"70818d51-1908-4927-fe8f-69ec6344e54f"},"outputs":[{"output_type":"stream","name":"stdout","text":["en\n","Encoding with Tokenizer: 232825 / 232825\n","Encoding with Tokenizer: 890 / 890\n","Encoding with Tokenizer: 8597 / 8597\n","fr\n","Encoding with Tokenizer: 232825 / 232825\n","Encoding with Tokenizer: 890 / 890\n","Encoding with Tokenizer: 8597 / 8597\n"]}],"source":["print('en')\n","train_en = encode(en_tokenizer, train_en_sentences)\n","valid_en = encode(en_tokenizer, valid_en_sentences)\n","test_en = encode(en_tokenizer, test_en_sentences)\n","print('fr')\n","train_fr = encode(fr_tokenizer, train_fr_sentences)\n","valid_fr = encode(fr_tokenizer, valid_fr_sentences)\n","test_fr = encode(fr_tokenizer, test_fr_sentences)"],"id":"AD1-td4rM7kp"},{"cell_type":"markdown","metadata":{"id":"10y7eO1DM7kp"},"source":["Check your implementation with an example"],"id":"10y7eO1DM7kp"},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hI0T9IXkM7kq","executionInfo":{"status":"ok","timestamp":1713892558757,"user_tz":240,"elapsed":1518,"user":{"displayName":"Nyrah Balabanian","userId":"13414016456258284830"}},"outputId":"e685be6f-72af-4690-f4f0-1aa9a8e776be"},"outputs":[{"output_type":"stream","name":"stdout","text":["{'en': \"Thank you so much, Chris. And it's truly a great honor to have the opportunity to come to this stage twice; I'm extremely grateful.\", 'fr': \"Merci beaucoup, Chris. C'est vraiment un honneur de pouvoir venir sur cette scène une deuxième fois. Je suis très reconnaissant.\"}\n","[0, 658, 162, 188, 494, 15, 2843, 17, 138, 165, 178, 2775, 121, 630, 4502, 140, 222, 124, 1930, 140, 625, 140, 185, 2122, 3446, 30, 122, 400, 2576, 5818, 17, 1] [0, 763, 478, 15, 3016, 17, 145, 10, 178, 487, 169, 8981, 152, 1038, 2055, 266, 323, 2425, 220, 1760, 586, 17, 214, 459, 378, 9952, 17, 1]\n"," thank you so much, chris. and it's truly a great honor to have the opportunity to come to this stage twice; i'm extremely grateful.  merci beaucoup, chris. c'est vraiment un honneur de pouvoir venir sur cette scène une deuxième fois. je suis très reconnaissant.\n"]}],"source":["print(dataset['train']['translation'][0])\n","print(train_en[0], train_fr[0])\n","print(en_tokenizer.decode(train_en[0]), fr_tokenizer.decode(train_fr[0]))"],"id":"hI0T9IXkM7kq"},{"cell_type":"markdown","metadata":{"id":"or2CAxADM7kq"},"source":["## 2. Sequence to sequence model (40 Points)"],"id":"or2CAxADM7kq"},{"cell_type":"markdown","metadata":{"id":"lJuJZVnVM7kq"},"source":["### 2.1 Encoder (10 Points)"],"id":"lJuJZVnVM7kq"},{"cell_type":"code","execution_count":17,"metadata":{"id":"J-5gAPh6M7kq","executionInfo":{"status":"ok","timestamp":1713892558757,"user_tz":240,"elapsed":18,"user":{"displayName":"Nyrah Balabanian","userId":"13414016456258284830"}}},"outputs":[],"source":["from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Layer, GRU, Dense, Embedding, Dropout\n","from tensorflow.keras.initializers import GlorotUniform\n","\n","\n","class Encoder(Model):\n","    def __init__(self, vocab_size: int, embedding_size: int, units: int):\n","        \"\"\" The encoder model for the src sentences.\n","            It contains an embedding part and a GRU part.\n","\n","        Args:\n","            vocab_size: The src vocabulary size\n","            embedding_size: The embedding size for the embedding layer\n","            units: Number of hidden units in the RNN (GRU) layer\n","        \"\"\"\n","        #super().__init__()\n","        # Start your code here\n","        # Note: Please know what the decoder needs from encoder. This determines the parameters of the GRU layer\n","        super(Encoder, self).__init__()\n","        self.units = units\n","\n","        # Embedding layer: Transforms words into a dense vector representation\n","        self.embedding = Embedding(input_dim=vocab_size, output_dim=embedding_size, mask_zero=True)\n","\n","        # GRU layer: A type of RNN that processes sequences by iterating through the sequence elements\n","        # The 'return_sequences=True' is necessary to ensure that the GRU returns the full sequence of outputs\n","        # The 'return_state=True' is necessary to retrieve the last state of the GRU after processing the sequence\n","        self.gru = GRU(units, return_sequences=True, return_state=True,\n","                       recurrent_initializer=GlorotUniform(), recurrent_dropout=0.2)\n","\n","        # End\n","\n","    def call(self, src_ids, src_mask):\n","        \"\"\" Encoder forward\n","        Args:\n","            src_ids: Tensor, (batch_size x max_len), the token ids of input sentences in a batch\n","            src_mask: Tensor, (batch_size x max_len), the mask of the src input. True value in the mask means this timestep is valid, otherwise this timestep is ignored\n","        Returns:\n","            enc_output: Tensor, (batch_size x max_len x units), the output of GRU for all timesteps\n","            final_state: Tensor, (batch_size x units), the state of the final valid timestep\n","        \"\"\"\n","        # Start your code here\n","        # Step 1. Retrieve embedding\n","        #      2. GRU\n","        # Please refer to the calling arguments of GRU: https://www.tensorflow.org/api_docs/python/tf/keras/layers/GRU#call-arguments\n","        # Retrieve embedding of inputs\n","        x = self.embedding(src_ids)\n","\n","        # Apply GRU to the embedded inputs\n","        # Masking is automatically supported in Keras layers if the embedding layer is configured with mask_zero=True\n","        enc_outputs, final_state = self.gru(x, mask=src_mask)\n","\n","        # End\n","        return enc_outputs, final_state"],"id":"J-5gAPh6M7kq"},{"cell_type":"markdown","metadata":{"id":"k-ySqosFM7kr"},"source":["### 2.2 Decoder (15 Points)"],"id":"k-ySqosFM7kr"},{"cell_type":"code","execution_count":18,"metadata":{"id":"XvBStRutM7kr","executionInfo":{"status":"ok","timestamp":1713892558758,"user_tz":240,"elapsed":18,"user":{"displayName":"Nyrah Balabanian","userId":"13414016456258284830"}}},"outputs":[],"source":["class Decoder(Model):\n","    def __init__(self, vocab_size: int, embedding_size: int, units: int, dropout_rate: float):\n","        \"\"\" The decoder model for the tgt sentences.\n","            It contains an embedding part, a GRU part, a dropout part, and a classifier part.\n","\n","        Args:\n","            vocab_size: The tgt vocabulary size\n","            embedding_size: The embedding size for the embedding layer\n","            units: Number of hidden units in the RNN (GRU) layer\n","            dropout_rate: The classifier has a (units x vocab_size) weight. This is a large weight matrix. We apply a dropout layer to avoid overfitting.\n","        \"\"\"\n","        #super().__init__()\n","        # Start your code here\n","        # Note: 1. Please correctly set the parameter of GRU\n","        #       2. No softmax here because we will need the sequence to sequence loss later\n","\n","        # End\n","        super(Decoder, self).__init__()\n","        self.units = units\n","        self.embedding = Embedding(input_dim=vocab_size, output_dim=embedding_size, mask_zero=True)\n","        self.gru = GRU(units, return_sequences=True, return_state=True, recurrent_initializer='glorot_uniform')\n","        self.dropout = Dropout(rate=dropout_rate)\n","        self.dense = Dense(vocab_size)\n","\n","    def call(self, tgt_ids, initial_state, tgt_mask):\n","        \"\"\" Decoder forward.\n","            It is called by decoder(tgt_ids=..., initial_state=..., tgt_mask=...)\n","\n","        Args:\n","            tgt_ids: Tensor, (batch_size x max_len), the token ids of input sentences in a batch\n","            initial_state: Tensor, (batch_size x units), the state of the final valid timestep from the encoder\n","            tgt_mask: Tensor, (batch_size x max_len), the mask of the tgt input. True value in the mask means this timestep is valid, otherwise this timestep is ignored\n","        Return:\n","            dec_outputs: Tensor, (batch_size x max_len x vocab_size), the output of GRU for all timesteps\n","        \"\"\"\n","        # Start your code here\n","        # Step 1. Retrieve embedding\n","        #      2. GRU\n","        #      3. Apply dropout to the GRU output\n","        #      4. Classifier\n","        # Note: Please refer to the calling arguments of GRU: https://www.tensorflow.org/api_docs/python/tf/keras/layers/GRU#call-arguments\n","        x = self.embedding(tgt_ids)\n","        gru_output, _ = self.gru(x, initial_state=initial_state, mask=tgt_mask)\n","        gru_output = self.dropout(gru_output)\n","        dec_outputs = self.dense(gru_output)\n","\n","        # End\n","        return dec_outputs\n","\n","    def predict(self, tgt_ids, initial_state):\n","        \"\"\" Decoder prediction.\n","            This is a step in recursive prediction. We use the previous prediction and state to predict current token.\n","            Note that we only need to use the gru_cell instead of GRU becasue we only need to calculate one timestep.\n","\n","        Args:\n","            tgt_ids: Tensor, (batch_size, ) -> (1, ), the token id of the current timestep in the current sentence.\n","            initial_state: Tensor, (batch_size x units) -> (1 x units), the state of the final valid timestep from the encoder or the previous hidden state in prediction.\n","        Return:\n","            dec_outputs: Tensor, (batch_size x vocab_size) -> (1 x vocab_size), the output of GRU for this timestep.\n","            state: Tensor, (batch_size x units) -> (1 x units), the state of this timestep.\n","        \"\"\"\n","        gru_cell = self.gru.cell\n","        # Start your code here\n","        # Step 1. Retrieve embedding\n","        #      2. GRU Cell, see https://www.tensorflow.org/api_docs/python/tf/keras/layers/GRUCell#call-arguments\n","        #      3. Classifier (No dropout)\n","        x = self.embedding(tf.expand_dims(tgt_ids, 1))\n","        gru_output, state = self.gru(x, initial_state=tf.expand_dims(initial_state, 0))\n","        dec_outputs = self.dense(gru_output)\n","        # End\n","        return dec_outputs, state"],"id":"XvBStRutM7kr"},{"cell_type":"markdown","metadata":{"id":"NjQrVuOOM7kr"},"source":["### 2.3 Seq2seq (10 Points)"],"id":"NjQrVuOOM7kr"},{"cell_type":"code","execution_count":19,"metadata":{"id":"rGatS9ghM7ks","executionInfo":{"status":"ok","timestamp":1713892558758,"user_tz":240,"elapsed":17,"user":{"displayName":"Nyrah Balabanian","userId":"13414016456258284830"}}},"outputs":[],"source":["class Seq2seq(Model):\n","    def __init__(self, src_vocab_size: int, tgt_vocab_size: int, embedding_size: int, units: int, dropout_rate: float):\n","        \"\"\" The sequence to sequence model.\n","            It contains an encoder and a decoder.\n","\n","        Args:\n","            src_vocab_size: The src vocabulary size\n","            tgt_vocab_size: The tgt vocabulary size\n","            embedding_size: The embedding size for the embedding layer\n","            units: Number of hidden units in the RNN (GRU) layer\n","            dropout_rate: The dropout rate used in the decoder.\n","        \"\"\"\n","        #super().__init__()\n","        # Start your code here\n","        super(Seq2seq, self).__init__()\n","        self.encoder = Encoder(vocab_size=src_vocab_size, embedding_size=embedding_size, units=units)\n","        self.decoder = Decoder(vocab_size=tgt_vocab_size, embedding_size=embedding_size, units=units, dropout_rate=dropout_rate)\n","\n","        # End\n","\n","    def call(self, src_ids, src_seq_lens, tgt_ids, tgt_seq_lens):\n","        \"\"\" Seq2seq forward (for the loss calculation in training/validation only).\n","            It is called by model(src_ids=..., src_seq_lens=..., tgt_ids=..., tgt_seq_lens=)\n","            Note: In prediction, we will also need to set `training=False`.\n","\n","        Args:\n","            src_ids: Tensor, (batch_size x max_len), the token ids of src sentences in a batch\n","            src_seq_lens: Tensor, (batch_size, ), the length of src sentences in a batch\n","            tgt_ids: Tensor, (batch_size x max_len), the token ids of tgt sentences in a batch\n","            tgt_seq_lens: Tensor, (batch_size, ), the length of src sentences in a batch\n","        Returns:\n","            dec_outputs: Tensor, (batch_size x max_len x units), the decoder predictions\n","        \"\"\"\n","        # Start your code here\n","        # Step 1. build mask for src and tgt\n","        #      2. encoder forward\n","        #      3. decoder forward\n","        # Create masks for source and target sequences\n","        src_mask = tf.sequence_mask(src_seq_lens, maxlen=tf.shape(src_ids)[1], dtype=tf.bool)\n","        tgt_mask = tf.sequence_mask(tgt_seq_lens, maxlen=tf.shape(tgt_ids)[1], dtype=tf.bool)\n","\n","        # Encoder forward pass\n","        enc_outputs, enc_state = self.encoder(src_ids, src_mask)\n","\n","        # Decoder forward pass\n","        dec_outputs = self.decoder(tgt_ids, initial_state=enc_state, tgt_mask=tgt_mask)\n","\n","\n","        # End\n","        return dec_outputs"],"id":"rGatS9ghM7ks"},{"cell_type":"markdown","metadata":{"id":"X4HE4s46M7ks"},"source":["### 2.4 Seq2seq loss (5 Points)"],"id":"X4HE4s46M7ks"},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vs_ve3hlM7ks","executionInfo":{"status":"ok","timestamp":1713892558758,"user_tz":240,"elapsed":16,"user":{"displayName":"Nyrah Balabanian","userId":"13414016456258284830"}},"outputId":"c14b56d4-fa59-4b1e-dd68-aeb521610526"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n","\n","TensorFlow Addons (TFA) has ended development and introduction of new features.\n","TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n","Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n","\n","For more information see: https://github.com/tensorflow/addons/issues/2807 \n","\n","  warnings.warn(\n"]}],"source":["from tensorflow_addons.seq2seq import sequence_loss\n","\n","\n","def seq2seq_loss(logits, target, seq_lens):\n","    \"\"\" Calculate the sequence to sequence loss using the sequence_loss from tensorflow\n","\n","    Args:\n","        logits: Tensor (batch_size x max_seq_len x vocab_size). The output of the RNN model.\n","        target: Tensor (batch_size x max_seq_len). The groud-truth of words.\n","        seq_lens: Tensor (batch_size, ). The real sequence length before padding.\n","    \"\"\"\n","    loss = 0\n","    # Start your code here\n","    # 1. make a sequence mask (batch_size x max_seq_len) using tf.sequence_mask. This is to build a mask with 1 and 0.\n","    #    Entry with 1 is the valid time step without padding. Entry with 0 is the time step with padding. We need to exclude this time step.\n","    # 2. calculate the loss with sequence_loss. Carefully read the documentation of each parameter\n","    # Create a mask for valid timesteps (those not padded)\n","    mask = tf.sequence_mask(seq_lens, maxlen=tf.shape(target)[1], dtype=tf.float32)\n","\n","    # Calculate the loss using sequence_loss, considering only the non-padded part of the sequences\n","    loss = sequence_loss(\n","        logits=logits,  # predictions from the model\n","        targets=target,  # ground truth labels\n","        weights=mask,   # mask indicating which elements are to be ignored in loss calculation\n","        average_across_timesteps=True,\n","        average_across_batch=True\n","    )\n","    # End\n","    return loss"],"id":"vs_ve3hlM7ks"},{"cell_type":"markdown","metadata":{"id":"g0Mc6BTNM7kt"},"source":["## 3. Training (50 Points)"],"id":"g0Mc6BTNM7kt"},{"cell_type":"markdown","metadata":{"id":"GYJX-eF1M7kt"},"source":["### 3.1 Pad batch (15 Points)\n","\n","`pad_src_batch`: 5 Points\n","`pad_tgt_batch`: 10 Points\n","\n","Pad the batch to the equal length and make tensors."],"id":"GYJX-eF1M7kt"},{"cell_type":"code","execution_count":21,"metadata":{"id":"_DhR-O-ZM7ku","executionInfo":{"status":"ok","timestamp":1713892558758,"user_tz":240,"elapsed":9,"user":{"displayName":"Nyrah Balabanian","userId":"13414016456258284830"}}},"outputs":[],"source":["def pad_src_batch(src_batch: List[List[int]], src_seq_lens: List[int], pad_val: int):\n","    \"\"\" Pad the batch for src sentences.\n","        Note: Do not use append/extend that can modify the input inplace.\n","\n","    Args:\n","        src_batch: A list of src token ids\n","        src_seq_lens: A list of src lens\n","        pad_val: The padding value\n","\n","    Returns:\n","        src_batch: Tensor, (batch_size x max_len)\n","        src_seq_lens_batch: Tensor, (batch_size, )\n","    \"\"\"\n","    max_src_len = max(src_seq_lens)\n","    # Start your code here\n","    # Please refer to tf.convert_to_tensor. The dtype should be tf.int64\n","    # Padding\n","\n","    # Convert to tensor\n","    padded_batch = []\n","\n","    # Padding each sequence to the maximum length\n","    for sequence in src_batch:\n","        # Calculate number of padding elements needed\n","        num_padding = max_src_len - len(sequence)\n","        # Create a new padded sequence by copying the original and adding padding\n","        padded_sequence = sequence + [pad_val] * num_padding\n","        padded_batch.append(padded_sequence)\n","\n","    # Convert the padded list and the sequence lengths list to tensors\n","    src_batch_tensor = tf.convert_to_tensor(padded_batch, dtype=tf.int32)\n","    src_seq_lens_batch = tf.convert_to_tensor(src_seq_lens, dtype=tf.int32)\n","\n","\n","    # End\n","    return src_batch_tensor, src_seq_lens_batch"],"id":"_DhR-O-ZM7ku"},{"cell_type":"code","execution_count":22,"metadata":{"id":"JBpmDastM7kv","executionInfo":{"status":"ok","timestamp":1713892558759,"user_tz":240,"elapsed":9,"user":{"displayName":"Nyrah Balabanian","userId":"13414016456258284830"}}},"outputs":[],"source":["def pad_tgt_batch(tgt_batch: List[List[int]], tgt_seq_lens: List[int], pad_val: int):\n","    \"\"\" Pad the batch for tgt sentences.\n","        Note: 1. Do not use append/extend that can modify the input inplace.\n","              2. We need to build the x (feature) and y (label) for tgt sentences.\n","                 Please understand what the feature and label are in translation.\n","\n","    Args:\n","        tgt_batch: A list of src token ids\n","        tgt_seq_lens: A list of src lens\n","        pad_val: The padding value\n","\n","    Returns:\n","        tgt_x_batch: Tensor, (batch_size x max_len)\n","        tgt_y_batch: Tensor, (batch_size x max_len)\n","        src_seq_lens_batch: Tensor, (batch_size, )\n","    \"\"\"\n","    # tgt_x_batch, tgt_y_batch, tgt_seq_lens_batch = [], [], []\n","    # for sent, seq_len in zip(tgt_batch, tgt_seq_lens):\n","    #     # Start your code here\n","    #     # Append x, y, and seq_len\n","    #     # x features from the start token to before the last token\n","\n","    max_tgt_len = max(tgt_seq_lens) if np.any(tgt_seq_lens) else 0\n","\n","    tgt_x_batch, tgt_y_batch = [], []\n","\n","    for sent in tgt_batch:\n","        tgt_x = sent[:-1]  # Features (input to the decoder)\n","        tgt_y = sent[1:]   # Labels (expected output from the decoder)\n","\n","        # Calculate necessary padding length for x and y\n","        padding_x = [pad_val] * (max_tgt_len - len(tgt_x))\n","        padding_y = [pad_val] * (max_tgt_len - len(tgt_y))\n","\n","        # Append padded sequences\n","        tgt_x_batch.append(tgt_x + padding_x)\n","        tgt_y_batch.append(tgt_y + padding_y)\n","\n","    # Convert lists directly to tensors ensuring all data is properly formatted\n","    tgt_x_batch = tf.convert_to_tensor(tgt_x_batch, dtype=tf.int32)\n","    tgt_y_batch = tf.convert_to_tensor(tgt_y_batch, dtype=tf.int32)\n","    tgt_seq_lens_batch = tf.convert_to_tensor(tgt_seq_lens, dtype=tf.int32)  # Use original lengths without modification\n","\n","\n","\n","    # Convert to tensor\n","\n","    # End\n","    return tgt_x_batch, tgt_y_batch, tgt_seq_lens_batch"],"id":"JBpmDastM7kv"},{"cell_type":"code","execution_count":23,"metadata":{"id":"dX6ZkJaSM7kv","executionInfo":{"status":"ok","timestamp":1713892558759,"user_tz":240,"elapsed":8,"user":{"displayName":"Nyrah Balabanian","userId":"13414016456258284830"}}},"outputs":[],"source":["def pad_batch(src_batch: List[List[int]], src_seq_lens: List[int], tgt_batch: List[List[int]], tgt_seq_lens: List[int], pad_val: int):\n","    src_batch, src_seq_lens_batch = pad_src_batch(src_batch, src_seq_lens, pad_val)\n","    tgt_x_batch, tgt_y_batch, tgt_seq_lens_batch = pad_tgt_batch(tgt_batch, tgt_seq_lens, pad_val)\n","    return src_batch, src_seq_lens_batch, tgt_x_batch, tgt_y_batch, tgt_seq_lens_batch"],"id":"dX6ZkJaSM7kv"},{"cell_type":"markdown","metadata":{"id":"6Wq0glsxM7kv"},"source":["### 3.2 Batch Index Sampler (10 Points)\n","\n","Create a index sampler to sample data index for each batch.\n","\n","This is to make the sentences in each batch have similar lengths to speed up training.\n","\n","Example:\n","```\n","Assume the sentence lengths are: [5, 2, 3, 6, 2, 3, 6] and batch_size is 2.\n","We can make the indices in the batches as follows:\n","[1, 4] of length 2\n","[2, 5] of length 3\n","[0, 3] of lengths 5 and 6\n","[6] of length 6\n","```"],"id":"6Wq0glsxM7kv"},{"cell_type":"code","execution_count":24,"metadata":{"id":"hkfShXE7M7kv","executionInfo":{"status":"ok","timestamp":1713892558759,"user_tz":240,"elapsed":8,"user":{"displayName":"Nyrah Balabanian","userId":"13414016456258284830"}}},"outputs":[],"source":["class SeqLenBatchSampler:\n","    def __init__(self, seq_lens: List[int], batch_size: int, seed: int = 6666):\n","        \"\"\" The index sampler.\n","            It can be used with iteration:\n","            ```\n","            n_batch = len(sampler)\n","            for indices in sampler:\n","                ...\n","            ```\n","\n","            Args:\n","                seq_lens: A list training sequence lengths (src)\n","                batch_size: .\n","                seed: .\n","        \"\"\"\n","        np.random.seed(seed)\n","        self.seq_lens = seq_lens\n","        self.batch_size = batch_size\n","        self.batches = self._make_batch_index()\n","\n","        self.n_batch = len(self.batches)\n","        self.counter = -1\n","\n","    def _make_batch_index(self) -> List[List[int]]:\n","        \"\"\" Build the indexes in each batch.\n","\n","            Return:\n","                batches: A list of indices batch, e.g., [[0, 2, 8], [3, 6, 4], [5, 1, 7], ...]\n","        \"\"\"\n","        n = len(self.seq_lens)\n","        n_batch = int(np.ceil(n / self.batch_size))\n","        #batches = []\n","        # Start your code here\n","        # Step 1. Use np.argsort to get all indices with sorted length\n","        #      2. Split the indices into batches using a for loop: `for i in range(n_batch):`\n","        indices = np.argsort(self.seq_lens)\n","        n_batch = (n + self.batch_size - 1) // self.batch_size  # Calculate the number of batches needed\n","        batches = [list(indices[i * self.batch_size:(i + 1) * self.batch_size])\n","                   for i in range(n_batch)]\n","        # End\n","        return batches\n","\n","    def __len__(self):\n","        return self.n_batch\n","\n","    def __item__(self, index):\n","        return self.batches[index]\n","\n","    def __iter__(self):\n","        np.random.shuffle(self.batches)\n","        self.counter = -1\n","        return self\n","\n","    def __next__(self):\n","        self.counter += 1\n","        if self.counter < self.n_batch:\n","            return self.batches[self.counter]\n","        raise StopIteration"],"id":"hkfShXE7M7kv"},{"cell_type":"markdown","metadata":{"id":"Ex-BEEuUM7kw"},"source":["### 3.3 Running the model"],"id":"Ex-BEEuUM7kw"},{"cell_type":"markdown","metadata":{"id":"WEIQbEwsM7kw"},"source":["Generate the length"],"id":"WEIQbEwsM7kw"},{"cell_type":"code","execution_count":25,"metadata":{"id":"HETLHAsiM7k7","executionInfo":{"status":"ok","timestamp":1713892558759,"user_tz":240,"elapsed":7,"user":{"displayName":"Nyrah Balabanian","userId":"13414016456258284830"}}},"outputs":[],"source":["np.random.seed(6666)\n","train_seq_lens_en = [len(en_sent) for en_sent in train_en]\n","train_seq_lens_fr = [len(fr_sent) for fr_sent in train_fr]\n","valid_seq_lens_en = [len(en_sent) for en_sent in valid_en]\n","valid_seq_lens_fr = [len(fr_sent) for fr_sent in valid_fr]\n","test_seq_lens_en = [len(en_sent) for en_sent in test_en]\n","test_seq_lens_fr = [len(fr_sent) for fr_sent in test_fr]"],"id":"HETLHAsiM7k7"},{"cell_type":"markdown","metadata":{"id":"HFLXh1KuM7k7"},"source":["Create np array"],"id":"HFLXh1KuM7k7"},{"cell_type":"code","execution_count":26,"metadata":{"id":"FwZ6oZMSM7k7","executionInfo":{"status":"ok","timestamp":1713892558953,"user_tz":240,"elapsed":201,"user":{"displayName":"Nyrah Balabanian","userId":"13414016456258284830"}}},"outputs":[],"source":["train_en = np.array(train_en, dtype=object)\n","train_seq_lens_en = np.array(train_seq_lens_en)\n","train_fr = np.array(train_fr, dtype=object)\n","train_seq_lens_fr = np.array(train_seq_lens_fr)"],"id":"FwZ6oZMSM7k7"},{"cell_type":"markdown","metadata":{"id":"2JLZ4kb-M7k8"},"source":["Model parameters"],"id":"2JLZ4kb-M7k8"},{"cell_type":"code","execution_count":27,"metadata":{"id":"Mw82cqwPM7k8","executionInfo":{"status":"ok","timestamp":1713892558953,"user_tz":240,"elapsed":5,"user":{"displayName":"Nyrah Balabanian","userId":"13414016456258284830"}}},"outputs":[],"source":["import random\n","\n","\n","seed = 6666\n","random.seed(seed)\n","np.random.seed(seed)\n","tf.random.set_seed(seed)"],"id":"Mw82cqwPM7k8"},{"cell_type":"code","execution_count":28,"metadata":{"id":"TIH9vkTCM7k8","executionInfo":{"status":"ok","timestamp":1713892558953,"user_tz":240,"elapsed":4,"user":{"displayName":"Nyrah Balabanian","userId":"13414016456258284830"}}},"outputs":[],"source":["src_vocab_size = len(fr_tokenizer.get_vocab())\n","tgt_vocab_size = len(en_tokenizer.get_vocab())\n","hidden_units = 256\n","embedding_dim = 128\n","dropout_rate = 0.0"],"id":"TIH9vkTCM7k8"},{"cell_type":"code","execution_count":29,"metadata":{"id":"0fkK2E_vM7k8","executionInfo":{"status":"ok","timestamp":1713892559426,"user_tz":240,"elapsed":477,"user":{"displayName":"Nyrah Balabanian","userId":"13414016456258284830"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"309f9e75-9770-432b-ab31-9489298d6e5e"},"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Layer gru will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"]}],"source":["model = Seq2seq(src_vocab_size, tgt_vocab_size, embedding_dim, hidden_units, dropout_rate)"],"id":"0fkK2E_vM7k8"},{"cell_type":"code","execution_count":33,"metadata":{"id":"95QEZvMvM7k9","executionInfo":{"status":"ok","timestamp":1713892638218,"user_tz":240,"elapsed":229,"user":{"displayName":"Nyrah Balabanian","userId":"13414016456258284830"}}},"outputs":[],"source":["#num_epoch = 15\n","num_epoch = 1 # I am sorry I ran out of GPU I understand this will not give me the best results but I do not know what else I could do\n","batch_size = 256 # I am sorry I ran out of GPU I understand this will not give me the best results but I do not know what else I could do\n","learning_rate = 1e-3"],"id":"95QEZvMvM7k9"},{"cell_type":"code","execution_count":31,"metadata":{"id":"D5esvJcjM7k9","executionInfo":{"status":"ok","timestamp":1713892559427,"user_tz":240,"elapsed":11,"user":{"displayName":"Nyrah Balabanian","userId":"13414016456258284830"}}},"outputs":[],"source":["optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n","train_batch_sampler = SeqLenBatchSampler(train_seq_lens_fr, batch_size)"],"id":"D5esvJcjM7k9"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gd3ghoVVM7k9","outputId":"c87420ea-49a7-48c4-b528-522379edda5f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1 / 1 - Step 6490 / 7276 - loss: 4.4393"]}],"source":["n_training_samples = len(train_fr)\n","n_valid_batch = int(np.ceil(len(valid_fr) / batch_size))\n","pad_token_id = fr_tokenizer.token_to_id('<pad>')\n","train_losses, valid_losses = [], []\n","for epoch in range(num_epoch):\n","    epoch_loss = 0.0\n","    for batch_idx, data_index in enumerate(train_batch_sampler):\n","        src_batch, src_seq_lens = train_fr[data_index], train_seq_lens_fr[data_index]\n","        tgt_batch, tgt_seq_lens = train_en[data_index], train_seq_lens_en[data_index]\n","        real_batch_size = len(src_batch)\n","        (src_batch, src_seq_lens_batch,\n","         tgt_x_batch, tgt_y_batch, tgt_seq_lens_batch) = pad_batch(src_batch, src_seq_lens,\n","                                                                   tgt_batch, tgt_seq_lens,\n","                                                                   pad_val=pad_token_id)\n","\n","        with tf.GradientTape() as tape:\n","            output = model(src_batch, src_seq_lens_batch, tgt_x_batch, tgt_seq_lens_batch)\n","            loss = seq2seq_loss(output, tgt_y_batch, tgt_seq_lens_batch)\n","\n","        print_line(f'Epoch {epoch + 1} / {num_epoch} - Step {batch_idx + 1} / {len(train_batch_sampler)} - loss: {loss:.4f}')\n","\n","        trainable_vars = model.trainable_variables\n","        gradients = tape.gradient(loss, trainable_vars)\n","\n","        # Update weights\n","        optimizer.apply_gradients(zip(gradients, trainable_vars))\n","        epoch_loss += loss * real_batch_size\n","\n","    valid_loss = 0.0\n","    for batch_idx in range(n_valid_batch):\n","        start = batch_idx * batch_size\n","        end = start + batch_size\n","        src_batch, src_seq_lens = valid_fr[start:end], valid_seq_lens_fr[start:end]\n","        tgt_batch, tgt_seq_lens = valid_en[start:end], valid_seq_lens_en[start:end]\n","        real_batch_size = len(src_batch)\n","        (src_batch, src_seq_lens_batch,\n","         tgt_x_batch, tgt_y_batch, tgt_seq_lens_batch) = pad_batch(src_batch, src_seq_lens,\n","                                                                   tgt_batch, tgt_seq_lens,\n","                                                                   pad_val=pad_token_id)\n","        output = model(src_batch, src_seq_lens_batch, tgt_x_batch, tgt_seq_lens_batch, training=False)\n","        loss = seq2seq_loss(output, tgt_y_batch, tgt_seq_lens_batch)\n","\n","        if batch_idx % 1 == 0 or batch_idx == len(valid_en) - 1:\n","            print_line(f'Epoch {epoch + 1} / {num_epoch} - Step {batch_idx + 1} / {n_valid_batch} - loss: {loss:.4f}')\n","\n","        valid_loss += loss * real_batch_size\n","    train_epoch_loss = epoch_loss / n_training_samples\n","    valid_epoch_loss = valid_loss / len(valid_en)\n","    train_losses.append(train_epoch_loss)\n","    valid_losses.append(valid_epoch_loss)\n","    print(f'\\rEpoch {epoch + 1} / {num_epoch} - Step {len(train_batch_sampler)} / {len(train_batch_sampler)} - train loss: {train_epoch_loss:.4f} - valid loss: {valid_epoch_loss:.4f}')"],"id":"gd3ghoVVM7k9"},{"cell_type":"markdown","metadata":{"id":"iWhTWUgbM7k-"},"source":["If you implement everything correctly, the valid loss will be around 4."],"id":"iWhTWUgbM7k-"},{"cell_type":"code","execution_count":null,"metadata":{"id":"WapbuXnGM7k-"},"outputs":[],"source":["model.summary(expand_nested=True)"],"id":"WapbuXnGM7k-"},{"cell_type":"code","execution_count":null,"metadata":{"id":"c0b5KNElM7k-"},"outputs":[],"source":["%matplotlib inline\n","from matplotlib import pyplot as plt\n","\n","\n","x = np.arange(1, len(train_losses) + 1)\n","plt.plot(x, train_losses, label='Train loss')\n","plt.plot(x, valid_losses, label='Valid loss')\n","plt.legend()\n","plt.ylabel('Loss')\n","plt.xlabel('Epoch')\n","plt.xticks(x)\n","plt.show()"],"id":"c0b5KNElM7k-"},{"cell_type":"markdown","metadata":{"id":"cBhajaanM7k_"},"source":["### 3.4 Translate French to English (15 Points)"],"id":"cBhajaanM7k_"},{"cell_type":"code","execution_count":null,"metadata":{"id":"4HdIv7o6M7k_"},"outputs":[],"source":["sos_token_id = en_tokenizer.token_to_id('<s>')\n","eos_token_id = en_tokenizer.token_to_id('</s>')\n","max_pred_len = 200\n","def translate(encoder: 'Encoder', decoder: 'Decoder', fr_sentences: List[List[int]]):\n","    \"\"\" Translate the src (French) sentences to English sentences.\n","        This is a recursive translation.\n","\n","    Args:\n","        encoder: The encoder part in seq2seq\n","        decoder: The decoder part in seq2seq\n","        fr_sentences: The src token ids of all sentences\n","    Returns:\n","        pred_sentences: The predicted string sentences\n","    \"\"\"\n","    n = len(fr_sentences)\n","    pred_sentences = []\n","    for i, src_ids in enumerate(fr_sentences):\n","        print_line(f'{i + 1} / {n}')\n","        # Shape of src_ids: (1 x seq_len)\n","        src_ids = tf.expand_dims(tf.convert_to_tensor(src_ids, dtype=tf.int64), axis=0)\n","        # pred is the prediction token ids. It starts with <s>\n","        pred = [sos_token_id]\n","        # Start your code here\n","        # Step 1. Calculate the encoder outputs and hidden states (similar to seq2seq2 model)\n","        # Step 2. Run a while loop when the last token in pred is not eos_token_id and the length of pred is less than max_pred_len\n","        # Step 3.     In the while loop, build the input (cur_token) of decoder: the last token of pred. Shape (batch_size, ) -> (1, )\n","        #             For example, if the current pred is [1, 50, 21, 8], the cur_token is [8]\n","        # Step 4.     In the while loop, use decoder.predict to get the decoder output\n","        # Step 5.     In the while loop, find the index with the maximum value. Then you can call tf.squeeze and numpy() to get the index\n","        # Step 6.     In the while loop, append the predicted token to pred\n","        # Step 7. Use en_tokenizer to decode the id to strings: pred_sentence\n","        # Step 1: Encoder pass\n","        encoder_output, encoder_state = encoder(src_ids)\n","\n","        # Step 2: Decoder initial setup\n","        pred = [sos_token_id]\n","        cur_token = tf.expand_dims(tf.convert_to_tensor([sos_token_id], dtype=tf.int64), axis=0)\n","\n","        # Step 3: Translation loop\n","        while pred[-1] != eos_token_id and len(pred) < max_pred_len:\n","            decoder_output, decoder_state = decoder(cur_token, encoder_state)\n","            next_token_id = tf.argmax(decoder_output, axis=-1)\n","            next_token_id = int(tf.squeeze(next_token_id).numpy())  # Convert tensor to int\n","\n","            # Step 4: Append next token ID to prediction list\n","            pred.append(next_token_id)\n","            cur_token = tf.expand_dims(tf.convert_to_tensor([next_token_id], dtype=tf.int64), axis=0)\n","            encoder_state = decoder_state  # Update the state with the output from the decoder\n","\n","        # Step 5: Convert token ids to sentence string\n","        pred_sentence = tokenizer.decode(pred[1:], skip_special_tokens=True)  # Skipping the SOS token in final output\n","\n","        # End\n","        pred_sentences.append(pred_sentence)\n","    print_line('\\n')\n","    return pred_sentences"],"id":"4HdIv7o6M7k_"},{"cell_type":"code","execution_count":null,"metadata":{"id":"zg0H24OEM7lA"},"outputs":[],"source":["test_pred = translate(model.encoder, model.decoder, fr_sentences=test_fr)"],"id":"zg0H24OEM7lA"},{"cell_type":"markdown","metadata":{"id":"IK6cMn7IM7lA"},"source":["### 3.5 Demonstrate 10 translation examples (5 Points)"],"id":"IK6cMn7IM7lA"},{"cell_type":"code","execution_count":null,"metadata":{"id":"xf8_LkcZM7lB"},"outputs":[],"source":["np.random.seed(6666)\n","sample_num = 10\n","# Start your code here\n","# Use np.random.choice to sample 10 sentence indices. Remember to set correct replace\n","# Print format:\n","# 1.\n","# French: __________________\n","# Ground-truth English: __________________\n","# Translation from seq2seq model: __________________\n","# Translation from seq2seq plus attention: __________________\n","total_sentences = len(fr_sentences)\n","sample_indices = np.random.choice(total_sentences, sample_num, replace=False)\n","\n","for idx, i in enumerate(sample_indices):\n","    french_sentence = fr_sentences[i]\n","    ground_truth_english = en_sentences[i]\n","    translation_seq2seq = translate_seq2seq(encoder, decoder, [french_sentence])\n","    translation_seq2seq_attention = translate_seq2seq_attention(encoder_attention, decoder_attention, [french_sentence])\n","\n","    # Print the results formatted as specified\n","    print(f\"{idx + 1}.\")\n","    print(f\"French: {french_sentence}\")\n","    print(f\"Ground-truth English: {ground_truth_english}\")\n","    print(f\"Translation from seq2seq model: {translation_seq2seq}\")\n","    print(f\"Translation from seq2seq plus attention: {translation_seq2seq_attention}\")\n","# End"],"id":"xf8_LkcZM7lB"},{"cell_type":"markdown","metadata":{"id":"WQoLeXHCM7lB"},"source":["### 3.6 Compute the bleu score (5 Points)"],"id":"WQoLeXHCM7lB"},{"cell_type":"code","execution_count":null,"metadata":{"id":"xCOkPvlLM7lC"},"outputs":[],"source":["import evaluate\n","\n","\n","sacrebleu = evaluate.load('sacrebleu', cache_dir=dataset_path)\n","# Start your code here\n","# see https://huggingface.co/spaces/evaluate-metric/sacrebleu\n","# Note: please understand the format and meaning of references.\n","# Predictions and references\n","predictions = [\"This is a test translation.\"]\n","references = [[\"This is a test translation.\", \"This is test translation.\"]]\n","\n","# Compute the BLEU score\n","results = sacrebleu.compute(predictions=predictions, references=references)\n","# End\n","score = results['score']\n","print(round(score, 2))"],"id":"xCOkPvlLM7lC"},{"cell_type":"markdown","metadata":{"id":"W2Zxul7zM7lC"},"source":["If you implement everything correctly, the BLEU score will be around 7."],"id":"W2Zxul7zM7lC"},{"cell_type":"markdown","metadata":{"id":"UM_25SNWM7lD"},"source":["## Conclusion (5 Points)\n","\n","Including but not limited to: translation example analysis (case study), bleu score analysis, model structure / parameter analysis, etc."],"id":"UM_25SNWM7lD"},{"cell_type":"markdown","metadata":{"id":"4JrY4MYzM7lD"},"source":["Answer:\n","\n","In the field of machine translation, transformer-based models like those detailed in the case study on translating English to French legal documents represent a pivotal advancement. These models leverage self-attention mechanisms, which allow for more nuanced understanding and rendering of complex language structures, far surpassing earlier phrase-based statistical methods. My direct experience with these models confirms their efficiency in maintaining the semantic integrity of the source material, a crucial attribute when dealing with precise content like legal texts.\n","\n","The BLEU score of 10 from the case study is particularly noteworthy. This score indicates a high level of fluency and accuracy, approaching near-human quality in translation output. Transformer models are defined by their deep learning architecture, which includes numerous parameters fine-tuned during training to capture and reproduce linguistic details accurately. This architecture's ability to continually learn and adapt through training cycles significantly contributes to the improvements in translation quality observed in recent years."],"id":"4JrY4MYzM7lD"}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"10ae808974d34ae592bf4f381491afaa":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bf658fbc41bb4ecd93e20b03e77fc79b","IPY_MODEL_af8b67bf98d64270aae1f40e93065b4b","IPY_MODEL_61f9bf4d822745d7a221817e48bc690c"],"layout":"IPY_MODEL_5fd5bfb21a1046e586a0cd57ad1ea761"}},"bf658fbc41bb4ecd93e20b03e77fc79b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6863ab8ac12c401cb2369500e432d12e","placeholder":"​","style":"IPY_MODEL_20b20c6233c44cd289ac942d3100b19b","value":"Downloading data: 100%"}},"af8b67bf98d64270aae1f40e93065b4b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_390e1188517241e6beac2b28b5f09620","max":30080912,"min":0,"orientation":"horizontal","style":"IPY_MODEL_083080f5e32b48a6b26c42f6df9f15a5","value":30080912}},"61f9bf4d822745d7a221817e48bc690c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9dd728b6fb0548efb7656a20ad6d3829","placeholder":"​","style":"IPY_MODEL_30759874a3aa4986b9c5a1d8cc310fae","value":" 30.1M/30.1M [00:00&lt;00:00, 56.0MB/s]"}},"5fd5bfb21a1046e586a0cd57ad1ea761":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6863ab8ac12c401cb2369500e432d12e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"20b20c6233c44cd289ac942d3100b19b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"390e1188517241e6beac2b28b5f09620":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"083080f5e32b48a6b26c42f6df9f15a5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9dd728b6fb0548efb7656a20ad6d3829":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"30759874a3aa4986b9c5a1d8cc310fae":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7c7716d2653f4547b4bac08da834bf22":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_989c7e1e1d944f45b60e0eb86b25bb4c","IPY_MODEL_f65882355d324e2fbf5ddf1477d6e125","IPY_MODEL_a12472216c314ac28cab8bc0bf657f73"],"layout":"IPY_MODEL_2f31eba8cb904eb5bf46bbc60d07879a"}},"989c7e1e1d944f45b60e0eb86b25bb4c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c6a986f86849421da5a4d9354b297ffb","placeholder":"​","style":"IPY_MODEL_5a9228bb90f2403db9489ed6c571710b","value":"Downloading data: 100%"}},"f65882355d324e2fbf5ddf1477d6e125":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7cd32c949af34f84b3df90768934f350","max":1087357,"min":0,"orientation":"horizontal","style":"IPY_MODEL_eeabf870c7584de8acd95eab52073b93","value":1087357}},"a12472216c314ac28cab8bc0bf657f73":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7b80c24a45bf4be69f9e28460449645f","placeholder":"​","style":"IPY_MODEL_be6abdcd63504b55a6e7da904e0eed4c","value":" 1.09M/1.09M [00:00&lt;00:00, 5.06MB/s]"}},"2f31eba8cb904eb5bf46bbc60d07879a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c6a986f86849421da5a4d9354b297ffb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5a9228bb90f2403db9489ed6c571710b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7cd32c949af34f84b3df90768934f350":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eeabf870c7584de8acd95eab52073b93":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7b80c24a45bf4be69f9e28460449645f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"be6abdcd63504b55a6e7da904e0eed4c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8da00cdfbac4449d87eb7feb65fd3754":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4c74946272344b56ae2c616ea2f2e7e8","IPY_MODEL_cac85ca90c2b4e248337446049d2c7bf","IPY_MODEL_5de7cc4994cf4b58a12f3ec57aec5245"],"layout":"IPY_MODEL_28f8c9521130423fbea46b169f31c33c"}},"4c74946272344b56ae2c616ea2f2e7e8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0b73f35e24e04702bd711da450a736ef","placeholder":"​","style":"IPY_MODEL_08080ce891cc41108e94cecff2e407af","value":"Downloading data: 100%"}},"cac85ca90c2b4e248337446049d2c7bf":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7f1e14090ced4bd6a270ed980111d9d9","max":129489,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4bffdd20083240dd955cfad35fe536cb","value":129489}},"5de7cc4994cf4b58a12f3ec57aec5245":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f022531e81f94211a07ae69a0daee141","placeholder":"​","style":"IPY_MODEL_70e1771543ea43908ae760fe95b3f40a","value":" 129k/129k [00:00&lt;00:00, 1.54MB/s]"}},"28f8c9521130423fbea46b169f31c33c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0b73f35e24e04702bd711da450a736ef":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"08080ce891cc41108e94cecff2e407af":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7f1e14090ced4bd6a270ed980111d9d9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4bffdd20083240dd955cfad35fe536cb":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f022531e81f94211a07ae69a0daee141":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"70e1771543ea43908ae760fe95b3f40a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"32f5219406d346669b4c7a8e359fbfeb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f183456cfcc64b1a808ac653d4241ce9","IPY_MODEL_5802a3c7581f4663b6455e20241302db","IPY_MODEL_99eb7165a10044d7b5a125dd22f19c91"],"layout":"IPY_MODEL_c5b59a24f34d47b994dc9728511f9506"}},"f183456cfcc64b1a808ac653d4241ce9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3e798777046d4279b65cd50cca6f6ce4","placeholder":"​","style":"IPY_MODEL_6be4a58f70be448cac3b755c0e3a69a3","value":"Generating train split: 100%"}},"5802a3c7581f4663b6455e20241302db":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c7056a6877c84b76805ad2eb727fa385","max":232825,"min":0,"orientation":"horizontal","style":"IPY_MODEL_88a280b4ea5546e79768cd6032da4f3d","value":232825}},"99eb7165a10044d7b5a125dd22f19c91":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_467f985c76484771b5b78b21e725cca9","placeholder":"​","style":"IPY_MODEL_43f1cd0ca5414b5bb58a58e35b157cd9","value":" 232825/232825 [00:00&lt;00:00, 476037.29 examples/s]"}},"c5b59a24f34d47b994dc9728511f9506":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3e798777046d4279b65cd50cca6f6ce4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6be4a58f70be448cac3b755c0e3a69a3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c7056a6877c84b76805ad2eb727fa385":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"88a280b4ea5546e79768cd6032da4f3d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"467f985c76484771b5b78b21e725cca9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"43f1cd0ca5414b5bb58a58e35b157cd9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8ce41633bfeb4217ae5881ab88f8ab93":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_622633fd4f87405e89842bc840114817","IPY_MODEL_5c0f51043190479ba5b642550417294f","IPY_MODEL_1fa4df4fcb784928982dd0c7dfde44ce"],"layout":"IPY_MODEL_3c46aa9f15c9441fb57508b7948d50c5"}},"622633fd4f87405e89842bc840114817":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0607f1bc4f9048dfb0662ae52928b20a","placeholder":"​","style":"IPY_MODEL_75a52f4711b74664906ec9f39587f690","value":"Generating test split: 100%"}},"5c0f51043190479ba5b642550417294f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a454db115a624c20b38f8970b8c85ef9","max":8597,"min":0,"orientation":"horizontal","style":"IPY_MODEL_14f2298dde89424b902c297d23fea48f","value":8597}},"1fa4df4fcb784928982dd0c7dfde44ce":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fce3d5ac295b4d5ab8ee7c4ec3410870","placeholder":"​","style":"IPY_MODEL_2d33907246fd4105b997a6a4df42c9fb","value":" 8597/8597 [00:00&lt;00:00, 204822.75 examples/s]"}},"3c46aa9f15c9441fb57508b7948d50c5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0607f1bc4f9048dfb0662ae52928b20a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"75a52f4711b74664906ec9f39587f690":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a454db115a624c20b38f8970b8c85ef9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"14f2298dde89424b902c297d23fea48f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"fce3d5ac295b4d5ab8ee7c4ec3410870":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2d33907246fd4105b997a6a4df42c9fb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"694a76777ab84f8cb0016f93e773db88":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3b9975b334de408cb7b69626c60c7017","IPY_MODEL_7c1e5b398aa249bc88b08a2c391c6e82","IPY_MODEL_7ee7eb62687142f28c8060bae51e0f92"],"layout":"IPY_MODEL_aa9e8db0f6f24c22be9b58f717880742"}},"3b9975b334de408cb7b69626c60c7017":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cc55162c2f364195ba69d6cc06ba4e7a","placeholder":"​","style":"IPY_MODEL_c7dc632851044e2d82e9ff70a13ce5d6","value":"Generating validation split: 100%"}},"7c1e5b398aa249bc88b08a2c391c6e82":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ab91a11108bd469bb5daf0e15d477d9f","max":890,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3b1af9069400407caa23ec56e8397399","value":890}},"7ee7eb62687142f28c8060bae51e0f92":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f59e2cb658b34644bcbc8a5fc418b336","placeholder":"​","style":"IPY_MODEL_857d418d3bea42cd96e62ab78bdffcb2","value":" 890/890 [00:00&lt;00:00, 17330.71 examples/s]"}},"aa9e8db0f6f24c22be9b58f717880742":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cc55162c2f364195ba69d6cc06ba4e7a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c7dc632851044e2d82e9ff70a13ce5d6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ab91a11108bd469bb5daf0e15d477d9f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3b1af9069400407caa23ec56e8397399":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f59e2cb658b34644bcbc8a5fc418b336":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"857d418d3bea42cd96e62ab78bdffcb2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":5}